{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data \n",
    "\n",
    "Once the data is successfuly downloaded from [https://gea.esac.esa.int/archive/](https://gea.esac.esa.int/archive/), and correctly decompressed following the instroctions provided in [Neeed to add link to README from personal github](add-link), we can now import the data on Python and store it as a data frame using the package [pandas](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional, add the following to the sql code to remove impurity in data:\n",
    "```sql\n",
    "WHERE gs.parallax < 5 * gs.parallax_error  -- Remove potential stars\n",
    "AND gs.ruwe < 1.4  -- Ensure good astrometric quality\n",
    "AND gs.phot_g_mean_mag < 21  -- Bright enough for good measurements\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    }
   ],
   "source": [
    "from src.data import data_download # Run Python file to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        source_id         ra       dec      pmra     pmdec  parallax  \\\n",
      "0   3470333738112  45.075505  0.152316 -1.072371 -3.191011  0.366321   \n",
      "1   5944234902272  44.884761  0.164806 -0.121274  0.725026 -0.395659   \n",
      "2   6459630980096  44.910498  0.189649  0.217806 -0.316007 -0.626561   \n",
      "3   9517648372480  45.254655  0.228999 -0.552941 -1.895446 -0.917219   \n",
      "4  10892037246720  45.188575  0.282424 -0.098037 -0.120580  0.001630   \n",
      "\n",
      "   parallax_error      ruwe  phot_g_mean_mag  nu_eff_used_in_astrometry  \\\n",
      "0        0.901633  0.889714        20.571114                   1.526179   \n",
      "1        1.340139  1.087911        20.704517                   1.647388   \n",
      "2        0.548536  1.020956        20.173105                        NaN   \n",
      "3        1.507964  1.031971        20.634562                        NaN   \n",
      "4        0.246332  0.974657        18.787239                   1.565118   \n",
      "\n",
      "   pmra_error  pmdec_error  pmra_pmdec_corr  astrometric_params_solved  \n",
      "0    1.552507     1.226259         0.207769                         31  \n",
      "1    1.482424     1.402002         0.285303                         31  \n",
      "2    0.679419     0.608799         0.260906                         95  \n",
      "3    1.988008     1.378176         0.212472                         95  \n",
      "4    0.257395     0.223107         0.164329                         31  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load into Pandas\n",
    "df = pd.read_csv(\"csv_files/qso_full_data.csv\")\n",
    "print(df.head())  # Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Content\n",
    "\n",
    "Before we procede, we need to understand what each column contains, to do so let us print the heading of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'ra', 'dec', 'pmra', 'pmdec', 'parallax', 'parallax_error',\n",
      "       'ruwe', 'phot_g_mean_mag', 'nu_eff_used_in_astrometry', 'pmra_error',\n",
      "       'pmdec_error', 'pmra_pmdec_corr', 'astrometric_params_solved'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above, displays:\n",
    "\n",
    "1. <b>source_id</b>, Unique Gaia identifier for the object\n",
    "2. <b>ra</b>, Right Ascension (celestial longitude) in degrees\n",
    "3. <b>dec</b>, Declination (celestial latitude) in degrees\n",
    "4. <b>pmra</b>, Proper motion in Right Ascension (mas/yr)\n",
    "5. <b>pmdec</b>, Proper motion in Declination (mas/yr)\n",
    "6. <b>parallax</b>, Parallax measurament (this is expected to be near zero for distant QSOs)\n",
    "7. <b>ruwe</b>, Renormalised Unit Weight Error (this indicates the quality of the data point)\n",
    "8. <b>phot_g_mean_mag</b>, Mean magnitude in Gaia's G-band \n",
    "9. <b>nu_eff_used_in_astrometry</b>, Efficient wavenumber denoted as $\\nu_{eff}$, this is used to charecterise the color of a celestial object by describing how its light is distributed across different wavelenghts.\n",
    "10. <b>parallax_error</b>, measure the uncentainty on parralax (standard deviation).\n",
    "11. <b>pmra_error</b>, Uncertainty in pmra.\n",
    "12. <b>pmdec_error</b>, Uncertainty in pmdec_error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make suere the data matches the description provided in the papaer, i.e. we expect there to be 1614173 sources which are identified as QSO-like objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data\n",
    "In this section we aim to remove potential outliers from the five parameter solution dataset.\n",
    "\n",
    "## Plan \n",
    "\n",
    "1. Initial Least Square Fit $\\rightarrow$ Fit the VSH model using all data.\n",
    "2. Compute $X^2$ Values $\\rightarrow$ For each QSO\n",
    "3. Compute the Median $\\rightarrow$ Compute the median of all $X$ values.\n",
    "4. Reject Outliers $\\rightarrow$ If $X>\\kappa \\times \\text{median}(X)$, mark the source as outlier.\n",
    "5. Refit $\\rightarrow$ Exclude outliers and re-run the fit.\n",
    "6. Iterate $\\rightarrow$ Repeate steps (e.g. 2-5) until convergence (i.e. outlier stops changing).\n",
    "\n",
    "## Procedure In EDR3\n",
    "1. Perform Least Square $\\rightarrow$ estimate VSH coefficients\n",
    "2. $\\kappa$-Clipping $\\rightarrow$ remove outliers\n",
    "3. Perform Bootstrapping $\\rightarrow$ quantify the uncertainty of results\n",
    "\n",
    "## Our approach\n",
    "Keep step 1 and 2 from EDR3, nut instrad:\n",
    "1. Perform Least Square $+$ $\\kappa$-Clipping $\\rightarrow$ filter the data\n",
    "2. Perform HMC (Bayesian inference) sampling on filtered dataset $\\rightarrow$ achieving posterior samples, with VSH coefficient estimate and uncertainities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from functools import partial, lru_cache\n",
    "from src.models.vsh_model import*\n",
    "import pandas as pd\n",
    "from iminuit import Minuit # to perform least square\n",
    "from src.models.configuration import*\n",
    "from src.data.data_utils import*\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_qso_dataframe()\n",
    "angles, obs, error = config_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_least_squares_fit(angles, obs, error, theta_init, lmax = 3, kappa=3.0, max_iter=10):\n",
    "\n",
    "    \n",
    "    alpha, delta = angles\n",
    "    mu_a_obs, mu_d_obs = obs\n",
    "    s_mu_a, s_mu_d, rho = error\n",
    "\n",
    "    keep = jnp.ones_like(alpha, dtype=bool)\n",
    "    theta = theta_init\n",
    "\n",
    "    prev_outliers = None\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        print('Iteration:', iteration+1)\n",
    "        alpha_k, delta_k = alpha[keep], delta[keep]\n",
    "        obs_k = (mu_a_obs[keep], mu_d_obs[keep])\n",
    "        err_k = (s_mu_a[keep], s_mu_d[keep], rho[keep])\n",
    "        angles_k = (alpha_k, delta_k)\n",
    "\n",
    "        def least_square_wrapper(*theta_flat):\n",
    "            theta_arr = jnp.array(theta_flat)\n",
    "            return least_square(angles_k, obs_k, err_k, theta_arr, lmax=lmax, grid=False)\n",
    "\n",
    "        m = Minuit(least_square_wrapper, *theta)\n",
    "        m.errordef = Minuit.LEAST_SQUARES\n",
    "\n",
    "        m.migrad()\n",
    "\n",
    "        theta = jnp.array([m.values[name] for name in m.parameters])\n",
    "\n",
    "        C0 = 1000/np.sqrt(8*np.pi/3)\n",
    "        C1 = 1000/np.sqrt(4*np.pi/3)\n",
    "\n",
    "        print(f'Current g components [μas/yr]: gx = {-theta[4]*C1}, gy = {theta[5]*C1}, gz = {theta[1]*C0}')\n",
    "\n",
    "        del m\n",
    "        gc.collect()\n",
    "        jax.clear_caches()\n",
    "\n",
    "        # Compute X^2 over full dataset (not just kept subset)\n",
    "        X = np.sqrt(compute_X2(alpha, delta, mu_a_obs, mu_d_obs, s_mu_a, s_mu_d, rho, theta, lmax))\n",
    "        median_X = jnp.median(X)\n",
    "        keep = X < kappa*median_X\n",
    "\n",
    "        print(f\"Rejected: {(~keep).sum()} sources\")\n",
    "\n",
    "        if prev_outliers is not None and jnp.array_equal(keep, prev_outliers):\n",
    "            print(f\"Converged after {iteration+1} iterations.\")\n",
    "            break\n",
    "        prev_outliers = keep\n",
    "\n",
    "    return theta, keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Current g components [μas/yr]: gx = -0.293548583984375, gy = -4.0919294357299805, gz = -2.8633511066436768\n",
      "Rejected: 3787 sources\n",
      "Iteration: 2\n",
      "Current g components [μas/yr]: gx = -0.1732703298330307, gy = -4.25071382522583, gz = -2.678118944168091\n",
      "Rejected: 3788 sources\n",
      "Iteration: 3\n",
      "Current g components [μas/yr]: gx = -0.16842861473560333, gy = -4.266857147216797, gz = -2.665255308151245\n",
      "Rejected: 3786 sources\n",
      "Iteration: 4\n",
      "Current g components [μas/yr]: gx = -0.16842861473560333, gy = -4.266857147216797, gz = -2.665255308151245\n",
      "Rejected: 3787 sources\n",
      "Iteration: 5\n",
      "Current g components [μas/yr]: gx = -0.13661928474903107, gy = -4.272395610809326, gz = -2.6614580154418945\n",
      "Rejected: 3785 sources\n",
      "Iteration: 6\n",
      "Current g components [μas/yr]: gx = -0.13488395512104034, gy = -4.272395610809326, gz = -2.6614580154418945\n",
      "Rejected: 3785 sources\n",
      "Converged after 6 iterations.\n",
      "Length of keep array: 1215942\n"
     ]
    }
   ],
   "source": [
    "lmax = 3\n",
    "total_params = count_vsh_coeffs(lmax)\n",
    "theta_init = jnp.zeros(total_params)\n",
    "\n",
    "theta, keep = robust_least_squares_fit(angles, obs, error, theta_init)\n",
    "\n",
    "print(f'Length of keep array: {len(keep)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.loc[np.array(keep)]\n",
    "# Saving filtered dataset\n",
    "df_clean.to_csv('csv_files/filtered_qso_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Least Square (for $l=1$ Toy Model)\n",
    "\n",
    "We successfully downloaded, loaded and filtered the data for 5 parameters solution, we defined the toroidal and spheroidal functions ($T_{lm}$ and $S_{lm}$), respectively modelling the right ascension (ra) and declination (dec). For $\\alpha \\in [0, 2\\pi]$ and $\\delta \\in [-\\pi/2,\\pi/2]$ we visualised the VSH vector fields. We now want to perform a MLE on the dataset.\n",
    "\n",
    "To do so, we will follow closely the procedure presented in the main paper (Gaia Early Data Release 3 Acceleration of the Solar System from Gaia astrometry). This assumes that the noise follows a Gaussian model, i.e. the astrometric measurement errors (in proper motion, parallax, etc.) are:\n",
    "- Unbiased (zero mean),\n",
    "- Independent between different sources (quasars),\n",
    "- With known standard deviation and correlations, as provided in Gaia EDR3.\n",
    "\n",
    "This allows the least-square estimation framework and the statistical significance tests, in particular using the $\\chi^2$ distributions for assessing power in VSH.\n",
    "\n",
    "Recall Eq. 5 amd 7:\n",
    "$$\n",
    "V(\\alpha, \\delta) = \\sum_{l=1}^{l_{\\text{max}}} \\left( t_{l0} T_{l0} + s_{l0} S_{l0}\n",
    "+ 2 \\sum_{m=1}^{l} \\left( t_{lm}^{\\mathbb{R}} T_{lm}^{\\mathbb{R}} - t_{lm}^{\\mathbb{I}} T_{lm}^{\\mathbb{I}} + s_{lm}^{\\mathbb{R}} S_{lm}^{\\mathbb{R}} - s_{lm}^{\\mathbb{I}} S_{lm}^{\\mathbb{I}} \\right) \\right)\\tag{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X^2 = \\begin{bmatrix}\n",
    "\\Delta\\mu_{\\alpha^*} & \\Delta\\mu_{\\delta} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\sigma_{\\mu_{\\alpha^*}}^2 & \\rho_{\\mu}\\sigma_{\\mu_{\\alpha^*}}\\sigma_{\\mu_{\\delta}} \\\\\n",
    "\\rho_{\\mu}\\sigma_{\\mu_{\\alpha^*}}\\sigma_{\\mu_{\\delta}} & \\sigma_{\\mu_{\\delta}}^2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\Delta\\mu_{\\alpha^*} \\\\ \\Delta\\mu_{\\delta} \n",
    "\\end{bmatrix}\\tag{7}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\Delta\\mu_{\\alpha^*} = \\mu_{\\alpha^* \\text{obs}} - V_{\\alpha^* \\text{model}}$ is the difference between observed and predicted proper motion right ascension (ra).\n",
    "- $\\Delta\\mu_{\\delta} = \\mu_{\\delta \\text{obs}} - V_{\\delta \\text{model}}$ is the difference between observed and predicted proper motion declination (dec).\n",
    "\n",
    "Since each proper motion componet is assumed to follow a Gaussian distribution, MLE simplifies to a weighted least squares. Hence our objective is to minimise Eq. 7:\n",
    "\n",
    "$$\n",
    "\\sum_k \\begin{bmatrix}\n",
    "\\Delta\\mu_{\\alpha^*} & \\Delta\\mu_{\\delta} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\sigma_{\\mu_{\\alpha^*}}^2 & \\rho_{\\mu}\\sigma_{\\mu_{\\alpha^*}}\\sigma_{\\mu_{\\delta}} \\\\\n",
    "\\rho_{\\mu}\\sigma_{\\mu_{\\alpha^*}}\\sigma_{\\mu_{\\delta}} & \\sigma_{\\mu_{\\delta}}^2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\Delta\\mu_{\\alpha^*} \\\\ \\Delta\\mu_{\\delta} \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are generating synthetic data to test our least square function and the coded VSH model (the VSH expansion Eq.5). We set $l_{max}=2$ when generating data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import generate_synthetic_data\n",
    "generate_synthetic_data # Generate synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load synthetic data and true coefficient values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_synthetic = pd.read_csv('synthetic_data/synthetic_vsh_data.csv') # loead synthetic \n",
    "true_coeff = np.load('synthetic_data/theta_true.npy') # loead true VSH coefficients\n",
    "angles_gen, obs_gen, error_gen = config_data(df_synthetic) # configurate the data for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iminuit import Minuit # to perform least square\n",
    "from src.models.configuration import*\n",
    "from src.data.data_utils import*\n",
    "from src.models.vsh_model import*\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, vmap\n",
    "from functools import partial, lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Toy Model \\& Model on Synthetic Data\n",
    "\n",
    "- First by fitting the least square (see function `toy_least_square` in [`src.models.vsh_model.py`](src/models/vsh_model.py)) with `iminuit`.\n",
    "- Additionaly testing both least square fit and HMC on universal vsh model and least square fucntion (respectivelly `model_vsh` and `least_square` and [`src.models.vsh_model.py`](src/models/vsh_model.py)).\n",
    "\n",
    "Note toy model only work for $l_{max}$ = 1, recall synthetic data was generated with $l=2$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Model Result l = 1:\n",
      "Fitted parameters values:\n",
      "[ 0.03217079  0.01450661  0.0113407   0.1311283   0.02000312 -0.06413274]\n",
      "True values:\n",
      "[ 0.05372004  0.05742959 -0.02012502 -0.00375978  0.00838665 -0.04013964]\n"
     ]
    }
   ],
   "source": [
    "# Bind fixed arguments into a new function\n",
    "bound_least_square = partial(toy_least_square, angles_gen, obs_gen, error_gen) \n",
    "\n",
    "# Now Minuit only sees the 6 free parameters\n",
    "m = Minuit(bound_least_square,\n",
    "           t_10=0.0, t_11r=0.0, t_11i=0.0,\n",
    "           s_10=0.0, s_11r=0.0, s_11i=0.0)\n",
    "\n",
    "m.errordef=Minuit.LEAST_SQUARES\n",
    "\n",
    "m.migrad()\n",
    "\n",
    "print('Toy Model Result l = 1:')\n",
    "theta_fit = jnp.array([m.values[k] for k in m.parameters])\n",
    "print(\"Fitted parameters values:\")\n",
    "print(theta_fit)\n",
    "print(\"True values:\")\n",
    "print(true_coeff[:count_vsh_coeffs(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least square with $l=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compleate least square result l = 1:\n",
      "Fitted parameters values:\n",
      "[ 0.03216825  0.13111432  0.01450038  0.01133812  0.02000075 -0.0641298 ]\n",
      "True values:\n",
      "[ 0.05372004  0.05742959 -0.02012502 -0.00375978  0.00838665 -0.04013964]\n"
     ]
    }
   ],
   "source": [
    "lmax = 1\n",
    "total_params = count_vsh_coeffs(lmax) \n",
    "\n",
    "# Flat vector theta: [t10, ..., t_lmaxm, s10, ..., s_lmaxm]\n",
    "theta_init = jnp.zeros(total_params)\n",
    "\n",
    "# Fix everything except theta\n",
    "def least_square_wrapper(*theta_flat):\n",
    "    theta = jnp.array(theta_flat)  # reconstructs the vector from scalars\n",
    "    return least_square(angles_gen, obs_gen, error_gen, theta, lmax=lmax, grid=False)\n",
    "\n",
    "m = Minuit(least_square_wrapper, *theta_init)\n",
    "\n",
    "m.errordef = Minuit.LEAST_SQUARES\n",
    "\n",
    "m.migrad()\n",
    "\n",
    "print('Compleate least square result l = 1:')\n",
    "theta_fit = jnp.array([m.values[k] for k in m.parameters])\n",
    "print(\"Fitted parameters values:\")\n",
    "print(theta_fit)\n",
    "print(\"True values:\")\n",
    "print(true_coeff[:count_vsh_coeffs(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least Square for $l=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compleate least square result l = 2:\n",
      "Fitted parameters values:\n",
      "[ 0.05237787  0.05555838 -0.02015737 -0.00370113  0.01000114 -0.0395992\n",
      " -0.01779413  0.02249806  0.03067211 -0.03782388  0.05861543 -0.05849521\n",
      "  0.01581841  0.0072174   0.0466077   0.05248069]\n",
      "True values:\n",
      "[ 0.05372004  0.05742959 -0.02012502 -0.00375978  0.00838665 -0.04013964\n",
      " -0.02277664  0.02273766  0.02961199 -0.03947825  0.05824246 -0.05696608\n",
      "  0.01680502  0.0075229   0.04790566  0.0521445 ]\n"
     ]
    }
   ],
   "source": [
    "lmax = 2\n",
    "total_params = count_vsh_coeffs(lmax) \n",
    "\n",
    "# Flat vector theta: [t10, ..., t_lmaxm, s10, ..., s_lmaxm]\n",
    "theta_init = jnp.zeros(total_params)\n",
    "\n",
    "# Fix everything except theta\n",
    "def least_square_wrapper(*theta_flat):\n",
    "    theta = jnp.array(theta_flat)  # reconstructs the vector from scalars\n",
    "    return least_square(angles_gen, obs_gen, error_gen, theta, lmax=lmax, grid=False)\n",
    "\n",
    "m = Minuit(least_square_wrapper, *theta_init)\n",
    "\n",
    "m.errordef = Minuit.LEAST_SQUARES\n",
    "\n",
    "m.migrad()\n",
    "\n",
    "print('Compleate least square result l = 2:')\n",
    "theta_fit = jnp.array([m.values[k] for k in m.parameters])\n",
    "print(\"Fitted parameters values:\")\n",
    "print(theta_fit)\n",
    "print(\"True values:\")\n",
    "print(true_coeff[:count_vsh_coeffs(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least square $l=3$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compleate least square result l = 2:\n",
      "Fitted parameters values:\n",
      "[ 0.03014502  0.03355306 -0.0007573   0.01433174  0.01033522 -0.01194067\n",
      " -0.01777831  0.00241366  0.02045461 -0.04025296  0.04289113 -0.06602865\n",
      "  0.00887562  0.01604122  0.03837589  0.01503773]\n",
      "True values:\n",
      "[ 0.05372004  0.05742959 -0.02012502 -0.00375978  0.00838665 -0.04013964\n",
      " -0.02277664  0.02273766  0.02961199 -0.03947825  0.05824246 -0.05696608\n",
      "  0.01680502  0.0075229   0.04790566  0.0521445 ]\n"
     ]
    }
   ],
   "source": [
    "lmax = 3\n",
    "total_params = count_vsh_coeffs(lmax) \n",
    "\n",
    "# Flat vector theta: [t10, ..., t_lmaxm, s10, ..., s_lmaxm]\n",
    "theta_init = jnp.zeros(total_params)\n",
    "\n",
    "# Fix everything except theta\n",
    "def least_square_wrapper(*theta_flat):\n",
    "    theta = jnp.array(theta_flat)  # reconstructs the vector from scalars\n",
    "    return least_square(angles_gen, obs_gen, error_gen, theta, lmax=lmax, grid=False)\n",
    "\n",
    "m = Minuit(least_square_wrapper, *theta_init)\n",
    "\n",
    "m.errordef = Minuit.LEAST_SQUARES\n",
    "\n",
    "m.migrad()\n",
    "\n",
    "print('Compleate least square result l = 2:')\n",
    "theta_fit = jnp.array([m.values[k] for k in m.parameters])\n",
    "print(\"Fitted parameters values:\")\n",
    "print(theta_fit[:count_vsh_coeffs(2)])\n",
    "print(\"True values:\")\n",
    "print(true_coeff[:count_vsh_coeffs(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test HMC Sampling on Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from numpyro.infer import NUTS, MCMC\n",
    "from numpyro.diagnostics import summary\n",
    "import numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_jit(angles, obs, error, theta, lmax):\n",
    "    return least_square(angles, obs, error, theta, lmax=lmax, grid=False)\n",
    "chi2_jit = jit(chi2_jit, static_argnames=['lmax'])\n",
    "\n",
    "# Define Model with Uniform prior\n",
    "def model_w_uni_prior(angles, obs, error, limit = 0.1, lmax = 3):\n",
    "    total_params = count_vsh_coeffs(lmax)\n",
    "    # Prior on all VSH coefficients (both toroidal and spheroidal)\n",
    "    theta = numpyro.sample(\"theta\", dist.Uniform(-limit, limit).expand([total_params]))\n",
    "    # Least-squares residuals: we assume Gaussian-distributed residuals\n",
    "    chi2_val = chi2_jit(angles, obs, error, theta, lmax=lmax)\n",
    "\n",
    "    # The log-likelihood is proportional to -0.5*chi^2\n",
    "    numpyro.factor(\"likelihood\", -0.5*chi2_val)\n",
    "\n",
    "# Definie Model with Gaussian Prior\n",
    "def model_w_norm_prior(angles, obs, error, std = 1, lmax = 3):\n",
    "\n",
    "    total_params = count_vsh_coeffs(lmax)\n",
    "    # Prior on all VSH coefficients (both toroidal and spheroidal)\n",
    "    theta = numpyro.sample(\"theta\", dist.Normal(0., std).expand([total_params]))\n",
    "    # Least-squares residuals: we assume Gaussian-distributed residuals\n",
    "    chi2_val = chi2_jit(angles, obs, error, theta, lmax=lmax)\n",
    "\n",
    "    # The log-likelihood is proportional to -0.5*chi^2\n",
    "    numpyro.factor(\"likelihood\", -0.5*chi2_val)\n",
    "\n",
    "\n",
    "n_s = 1000 # number of samples\n",
    "n_warmup = 2000 #  number of warmups \n",
    "n_chains = 3 # numbe of chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:   4%|▍         | 119/3000 [00:36<14:36,  3.29it/s, 1023 steps of size 1.08e-03. acc. prob=0.70]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m kernel_uni \u001b[38;5;241m=\u001b[39m NUTS(model_w_uni_prior, target_accept_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m) \u001b[38;5;66;03m# this is to make sure acceptance does not exceed 90%\u001b[39;00m\n\u001b[1;32m      5\u001b[0m mcmc_uni \u001b[38;5;241m=\u001b[39m MCMC(kernel_uni, num_warmup\u001b[38;5;241m=\u001b[39mn_warmup, num_samples\u001b[38;5;241m=\u001b[39mn_s, num_chains\u001b[38;5;241m=\u001b[39mn_chains, chain_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m'\u001b[39m, progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmcmc_uni\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangles\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mangles_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobs_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43merror_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m ps_w_uni_prior \u001b[38;5;241m=\u001b[39m mcmc_uni\u001b[38;5;241m.\u001b[39mget_samples()\n\u001b[1;32m      9\u001b[0m diagnostics \u001b[38;5;241m=\u001b[39m summary(mcmc_uni\u001b[38;5;241m.\u001b[39mget_samples(group_by_chain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m~/Document/Gaia_Project/mem97/gaia_venv/lib/python3.12/site-packages/numpyro/infer/mcmc.py:706\u001b[0m, in \u001b[0;36mMCMC.run\u001b[0;34m(self, rng_key, extra_fields, init_params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchain_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 706\u001b[0m         states, last_state \u001b[38;5;241m=\u001b[39m \u001b[43m_laxmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_map_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchain_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    708\u001b[0m         states, last_state \u001b[38;5;241m=\u001b[39m pmap(partial_map_fn)(map_args)\n",
      "File \u001b[0;32m~/Document/Gaia_Project/mem97/gaia_venv/lib/python3.12/site-packages/numpyro/infer/mcmc.py:177\u001b[0m, in \u001b[0;36m_laxmap\u001b[0;34m(f, xs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m    176\u001b[0m     x \u001b[38;5;241m=\u001b[39m jit(_get_value_from_index)(xs, i)\n\u001b[0;32m--> 177\u001b[0m     ys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: jnp\u001b[38;5;241m.\u001b[39mstack(args), \u001b[38;5;241m*\u001b[39mys)\n",
      "File \u001b[0;32m~/Document/Gaia_Project/mem97/gaia_venv/lib/python3.12/site-packages/numpyro/infer/mcmc.py:489\u001b[0m, in \u001b[0;36mMCMC._single_chain_mcmc\u001b[0;34m(self, init, args, kwargs, collect_fields, remove_sites)\u001b[0m\n\u001b[1;32m    483\u001b[0m collection_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    484\u001b[0m collection_size \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    485\u001b[0m     collection_size\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collection_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m collection_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthinning\n\u001b[1;32m    488\u001b[0m )\n\u001b[0;32m--> 489\u001b[0m collect_vals \u001b[38;5;241m=\u001b[39m \u001b[43mfori_collect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlower_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupper_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_collect_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpostprocess_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_fields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_sites\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_last_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthinning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthinning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogbar_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_get_progbar_desc_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiagnostics_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiagnostics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_chains\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m states, last_val \u001b[38;5;241m=\u001b[39m collect_vals\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Get first argument of type `HMCState`\u001b[39;00m\n",
      "File \u001b[0;32m~/Document/Gaia_Project/mem97/gaia_venv/lib/python3.12/site-packages/numpyro/util.py:399\u001b[0m, in \u001b[0;36mfori_collect\u001b[0;34m(lower, upper, body_fun, init_val, transform, progbar, return_last_val, collection_size, thinning, **progbar_opts)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(upper) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m--> 399\u001b[0m         vals \u001b[38;5;241m=\u001b[39m \u001b[43m_body_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m         t\u001b[38;5;241m.\u001b[39mset_description(progbar_desc(i), refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m diagnostics_fn:\n",
      "File \u001b[0;32m~/Document/Gaia_Project/mem97/gaia_venv/lib/python3.12/site-packages/jax/_src/prng.py:328\u001b[0m, in \u001b[0;36mprngkeyarray_unflatten\u001b[0;34m(impl, children)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprngkeyarray_flatten\u001b[39m(x):\n\u001b[1;32m    326\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (x\u001b[38;5;241m.\u001b[39m_base_array,), x\u001b[38;5;241m.\u001b[39m_impl\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprngkeyarray_unflatten\u001b[39m(impl, children):\n\u001b[1;32m    329\u001b[0m   base_array, \u001b[38;5;241m=\u001b[39m children\n\u001b[1;32m    330\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m PRNGKeyArray(impl, base_array)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = np.random.randint(1, 101)\n",
    "rng_key = jax.random.key(x)\n",
    "\n",
    "kernel_uni = NUTS(model_w_uni_prior, target_accept_prob=0.75) # this is to make sure acceptance does not exceed 90%\n",
    "mcmc_uni = MCMC(kernel_uni, num_warmup=n_warmup, num_samples=n_s, num_chains=n_chains, chain_method='sequential', progress_bar=True)\n",
    "mcmc_uni.run(rng_key, angles = angles_gen, obs = obs_gen, error = error_gen, limit = 1, lmax=3)\n",
    "ps_w_uni_prior = mcmc_uni.get_samples()\n",
    "\n",
    "diagnostics = summary(mcmc_uni.get_samples(group_by_chain=True))\n",
    "divergences = mcmc_uni.get_extra_fields()[\"diverging\"]  # shape: (num_samples * num_chains,)\n",
    "num_divergences = divergences.sum()\n",
    "print(\"Number of divergences:\", num_divergences)\n",
    "\n",
    "del mcmc_uni\n",
    "gc.collect()\n",
    "jax.clear_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(1, 101)\n",
    "rng_key = jax.random.key(x)\n",
    "\n",
    "kernel_norm = NUTS(model_w_norm_prior, target_accept_prob=0.75)\n",
    "mcmc_norm = MCMC(kernel_norm, num_warmup=n_warmup, num_samples=n_s, num_chains=n_chains, progress_bar=True)\n",
    "mcmc_norm.run(rng_key, angles = angles_gen, obs = obs_gen, error = error_gen, std = 1, lmax=3)\n",
    "\n",
    "ps_w_norm_prior = mcmc_norm.get_samples()\n",
    "\n",
    "mcmc_norm.print_summary()\n",
    "del mcmc_norm\n",
    "gc.collect()\n",
    "jax.clear_caches()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
