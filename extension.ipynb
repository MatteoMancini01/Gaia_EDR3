{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04eeffab",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "Notebook designed to run extension experiments, these experiments include \n",
    "-\tPower spectrum plots\n",
    "-\tPerform inference for different clipping values\n",
    "\n",
    "First, we want to run HMC for different values of $l_{max}$ on the full dataset, just like we did to produce Figure 7 in the original paper. This time our goal is to save the samples and their respective diagnostics, so that we can work on any other potential extensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0565df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "from numpyro.infer import NUTS, MCMC, Predictive\n",
    "from numpyro import handlers\n",
    "from numpyro.diagnostics import summary, autocorrelation\n",
    "import numpyro.distributions as dist\n",
    "from src.models.vsh_model import*\n",
    "from src.models.configuration import*\n",
    "from src.data.data_utils import*\n",
    "from src.save_load_pkl.save_load import*\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7558b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_filtered_qso_df() # load filtered data\n",
    "angles, obs, error = config_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42344d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_jit(angles, obs, error, theta, lmax):\n",
    "    return least_square(angles, obs, error, theta, lmax=lmax, grid=False)\n",
    "chi2_jit = jit(chi2_jit, static_argnames=['lmax'])\n",
    "\n",
    "\n",
    "def model_for_HMC(angles, obs, error, lmax):\n",
    "    total_params = count_vsh_coeffs(lmax)\n",
    "    \n",
    "    # Prior on all VSH coefficients (both toroidal and spheroidal)\n",
    "    theta = numpyro.sample(\"theta\", dist.Normal(0.0, 1.0).expand([total_params]))\n",
    "    # Least-squares residuals: we assume Gaussian-distributed residuals\n",
    "    chi2_val = chi2_jit(angles, obs, error, theta, lmax=lmax)\n",
    "\n",
    "    # The log-likelihood is proportional to -0.5*chi^2\n",
    "    numpyro.factor(\"likelihood\", -0.5*chi2_val)\n",
    "\n",
    "n_s = 5000 # number of samples\n",
    "n_warmup = 2000 #  number of warmups \n",
    "n_chains = 6 # numbe of chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d49ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]2025-06-21 15:20:49.040540: E external/xla/xla/service/slow_operation_alarm.cc:73] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %multiply.1986 = f32[1212154]{0} multiply(%constant.2838, %broadcast.1601), metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(T_lm)/jit(T_lm_scalar)/jvp(jit(Y_lm))/mul\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=198}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2025-06-21 15:20:49.042940: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 6.459193512s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %multiply.1986 = f32[1212154]{0} multiply(%constant.2838, %broadcast.1601), metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(T_lm)/jit(T_lm_scalar)/jvp(jit(Y_lm))/mul\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=198}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "sample: 100%|██████████| 7000/7000 [01:35<00:00, 73.65it/s, 7 steps of size 2.08e-01. acc. prob=0.89] \n",
      "sample: 100%|██████████| 7000/7000 [01:24<00:00, 82.97it/s, 7 steps of size 2.25e-01. acc. prob=0.87]  \n",
      "sample: 100%|██████████| 7000/7000 [01:25<00:00, 82.35it/s, 7 steps of size 2.24e-01. acc. prob=0.87]\n",
      "sample: 100%|██████████| 7000/7000 [01:27<00:00, 80.40it/s, 7 steps of size 2.07e-01. acc. prob=0.89] \n",
      "sample: 100%|██████████| 7000/7000 [01:22<00:00, 84.86it/s, 3 steps of size 2.38e-01. acc. prob=0.86]\n",
      "sample: 100%|██████████| 7000/7000 [01:20<00:00, 86.66it/s, 3 steps of size 2.55e-01. acc. prob=0.83]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 2\n",
      "Average r_hat: 1.0000461\n",
      "Number of divergences: 0\n",
      "l = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]2025-06-21 15:29:34.916909: E external/xla/xla/service/slow_operation_alarm.cc:73] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %multiply.6533 = c64[1212154,3]{1,0} multiply(%broadcast.4275, %constant.6969), metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(S_lm)/jit(S_lm_scalar)/mul\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=559}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2025-06-21 15:29:28.499969: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took -424.36079ms\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %multiply.6533 = c64[1212154,3]{1,0} multiply(%broadcast.4275, %constant.6969), metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(S_lm)/jit(S_lm_scalar)/mul\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=559}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "sample: 100%|██████████| 7000/7000 [02:20<00:00, 49.99it/s, 7 steps of size 1.72e-01. acc. prob=0.87] \n",
      "sample: 100%|██████████| 7000/7000 [02:13<00:00, 52.31it/s, 7 steps of size 1.60e-01. acc. prob=0.89] \n",
      "sample: 100%|██████████| 7000/7000 [02:10<00:00, 53.76it/s, 7 steps of size 1.90e-01. acc. prob=0.84]\n",
      "sample: 100%|██████████| 7000/7000 [02:09<00:00, 54.22it/s, 7 steps of size 1.62e-01. acc. prob=0.89] \n",
      "sample: 100%|██████████| 7000/7000 [02:07<00:00, 54.96it/s, 7 steps of size 1.84e-01. acc. prob=0.85] \n",
      "sample: 100%|██████████| 7000/7000 [02:08<00:00, 54.63it/s, 7 steps of size 1.79e-01. acc. prob=0.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 1\n",
      "Average r_hat: 0.99993956\n",
      "Number of divergences: 0\n",
      "l = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7000 [00:00<?, ?it/s]2025-06-21 15:42:46.123251: E external/xla/xla/service/slow_operation_alarm.cc:73] Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  %concatenate.192 = f32[1212154,3]{1,0} concatenate(%constant.8972, %constant.8976, %broadcast.7631), dimensions={1}, metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(T_lm)/jit(T_lm_scalar)/jit(basis_vectors)/concatenate\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=288}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2025-06-21 15:42:46.191041: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 6.11236804s\n",
      "Constant folding an instruction is taking > 4s:\n",
      "\n",
      "  %concatenate.192 = f32[1212154,3]{1,0} concatenate(%constant.8972, %constant.8976, %broadcast.7631), dimensions={1}, metadata={op_name=\"jit(_body_fn)/jit(main)/while/body/while/body/jvp(jit(chi2_jit))/jit(least_square)/vmap(jit(model_vsh))/jit(T_lm)/jit(T_lm_scalar)/jit(basis_vectors)/concatenate\" source_file=\"/home/riccardo_mancini/Gaia_EDR3/src/models/vsh_model.py\" source_line=288}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "sample: 100%|██████████| 7000/7000 [03:39<00:00, 31.92it/s, 7 steps of size 1.48e-01. acc. prob=0.86] \n",
      "sample: 100%|██████████| 7000/7000 [22:51<00:00,  5.10it/s, 7 steps of size 1.59e-01. acc. prob=0.84] \n",
      "sample: 100%|██████████| 7000/7000 [02:46<00:00, 41.98it/s, 15 steps of size 1.45e-01. acc. prob=0.87] \n",
      "sample: 100%|██████████| 7000/7000 [02:51<00:00, 40.90it/s, 15 steps of size 1.51e-01. acc. prob=0.86]\n",
      "sample: 100%|██████████| 7000/7000 [02:45<00:00, 42.33it/s, 7 steps of size 1.55e-01. acc. prob=0.85] \n",
      "sample: 100%|██████████| 7000/7000 [03:08<00:00, 37.14it/s, 7 steps of size 1.37e-01. acc. prob=0.88]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 2\n",
      "Average r_hat: 0.99999595\n",
      "Number of divergences: 0\n",
      "l = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 7000/7000 [05:40<00:00, 20.53it/s, 15 steps of size 1.33e-01. acc. prob=0.85]\n",
      "sample: 100%|██████████| 7000/7000 [04:30<00:00, 25.84it/s, 7 steps of size 1.36e-01. acc. prob=0.85] \n",
      "sample: 100%|██████████| 7000/7000 [04:22<00:00, 26.67it/s, 15 steps of size 1.41e-01. acc. prob=0.83]\n",
      "sample: 100%|██████████| 7000/7000 [04:03<00:00, 28.69it/s, 7 steps of size 1.44e-01. acc. prob=0.83] \n",
      "sample: 100%|██████████| 7000/7000 [04:23<00:00, 26.52it/s, 15 steps of size 1.39e-01. acc. prob=0.84] \n",
      "sample: 100%|██████████| 7000/7000 [04:47<00:00, 24.31it/s, 7 steps of size 1.33e-01. acc. prob=0.85] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 2\n",
      "Average r_hat: 1.0000026\n",
      "Number of divergences: 0\n",
      "l = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 7000/7000 [08:23<00:00, 13.89it/s, 15 steps of size 1.24e-01. acc. prob=0.84]   \n",
      "sample: 100%|██████████| 7000/7000 [07:14<00:00, 16.12it/s, 15 steps of size 1.27e-01. acc. prob=0.83]  \n",
      "sample: 100%|██████████| 7000/7000 [07:17<00:00, 16.01it/s, 15 steps of size 1.27e-01. acc. prob=0.84]  \n",
      "sample: 100%|██████████| 7000/7000 [07:31<00:00, 15.50it/s, 15 steps of size 1.24e-01. acc. prob=0.84]  \n",
      "sample: 100%|██████████| 7000/7000 [07:57<00:00, 14.66it/s, 15 steps of size 1.08e-01. acc. prob=0.88]  \n",
      "sample: 100%|██████████| 7000/7000 [07:23<00:00, 15.79it/s, 7 steps of size 1.26e-01. acc. prob=0.84]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 2\n",
      "Average r_hat: 0.999972\n",
      "Number of divergences: 0\n",
      "l = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 7000/7000 [12:18<00:00,  9.48it/s, 15 steps of size 1.05e-01. acc. prob=0.87]   \n",
      "sample: 100%|██████████| 7000/7000 [11:09<00:00, 10.45it/s, 15 steps of size 1.08e-01. acc. prob=0.85]  \n",
      "sample: 100%|██████████| 7000/7000 [11:07<00:00, 10.49it/s, 31 steps of size 1.06e-01. acc. prob=0.87]  \n",
      "sample: 100%|██████████| 7000/7000 [10:57<00:00, 10.64it/s, 15 steps of size 1.18e-01. acc. prob=0.83]  \n",
      "sample: 100%|██████████| 7000/7000 [10:55<00:00, 10.67it/s, 15 steps of size 1.10e-01. acc. prob=0.85]  \n",
      "sample: 100%|██████████| 7000/7000 [10:46<00:00, 10.83it/s, 7 steps of size 1.19e-01. acc. prob=0.83]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 2\n",
      "Average r_hat: 0.9999835\n",
      "Number of divergences: 0\n",
      "l = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 7000/7000 [16:42<00:00,  6.98it/s, 15 steps of size 1.04e-01. acc. prob=0.85]   \n",
      "sample: 100%|██████████| 7000/7000 [15:31<00:00,  7.52it/s, 15 steps of size 1.18e-01. acc. prob=0.80]  \n",
      "sample: 100%|██████████| 7000/7000 [15:12<00:00,  7.67it/s, 31 steps of size 1.05e-01. acc. prob=0.84]  \n",
      "sample: 100%|██████████| 7000/7000 [15:08<00:00,  7.70it/s, 15 steps of size 1.05e-01. acc. prob=0.84]  \n",
      "sample: 100%|██████████| 7000/7000 [15:00<00:00,  7.78it/s, 15 steps of size 1.04e-01. acc. prob=0.84]  \n",
      "sample: 100%|██████████| 7000/7000 [15:51<00:00,  7.36it/s, 31 steps of size 1.19e-01. acc. prob=0.80]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation length estimate: 3\n",
      "Average r_hat: 1.000038\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.key(0)\n",
    "\n",
    "kernel = NUTS(model_for_HMC, target_accept_prob=0.75) # this is to make sure acceptance does not exceed 90%\n",
    "\n",
    "posterior_samples = [] # collect posterior samples based on l\n",
    "iat_values = []\n",
    "for l in range(1, 8):\n",
    "    print(f'l = {l}')\n",
    "    # Run sampling algoeithm (HMC)\n",
    "    mcmc = MCMC(kernel, num_warmup=n_warmup, num_samples=n_s, num_chains=n_chains, chain_method='sequential', progress_bar=True)\n",
    "    mcmc.run(rng_key, angles = angles, obs = obs, error = error, lmax=l)\n",
    "    ps = mcmc.get_samples()\n",
    "    posterior_samples.append(ps)\n",
    "    \n",
    "    diagnostics = summary(mcmc.get_samples(group_by_chain=True))\n",
    "    n_eff = diagnostics['theta']['n_eff']\n",
    "    iat = estimate_iat(n_s, n_chains, n_eff, index=[1,4,5])\n",
    "    iat_values.append(iat)\n",
    "    print(f'Autocorrelation length estimate: {iat}')\n",
    "\n",
    "    r_hats = diagnostics['theta']['r_hat']\n",
    "    avg_r_hat = np.sum(r_hats) / len(r_hats)\n",
    "    print(\"Average r_hat:\", avg_r_hat)\n",
    "\n",
    "    divergences = mcmc.get_extra_fields()[\"diverging\"]  # shape: (num_samples * num_chains,)\n",
    "    num_divergences = divergences.sum()\n",
    "    print(\"Number of divergences:\", num_divergences)\n",
    "\n",
    "    # == Save results ==\n",
    "    save_pickle(f'lmax_{l}', posterior_samples, dir = 'hmc_samples/posterior_samples')\n",
    "    save_pickle(f'lmax_{l}', diagnostics, dir = 'hmc_samples/diagnostic_hmc')\n",
    "    \n",
    "    # Free memory after each iteration\n",
    "    del mcmc\n",
    "    gc.collect()\n",
    "    jax.clear_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32f84bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "posterior_sample_norm = load_pickle('lmax_1', dir = 'hmc_samples/posterior_samples')[0]\n",
    "diagnostics = load_pickle('lmax_1', dir = 'hmc_samples/diagnostic_hmc')\n",
    "n_eff = diagnostics['theta']['n_eff']\n",
    "iat = estimate_iat(n_s, n_chains, n_eff, index=[1,4,5])\n",
    "print(iat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67e545af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_m = cov_matrix_hmc(posterior_sample_norm['theta'][::iat], indices=[1,4,5])\n",
    "result_uni = jnp.mean(posterior_sample_norm['theta'], axis = 0)\n",
    "params = [result_uni[1], result_uni[4], result_uni[5]]\n",
    "\n",
    "summary_norm, v_vec, v_Sigma,_ = vsh_vector_summary(params, cov_m)\n",
    "summary_norm_gal, v_vec_gal, v_Sigma_gal, _ = vsh_vector_summary_galactic(v_vec, v_Sigma)\n",
    "\n",
    "lb_summary_ = lb_summary(v_vec_gal, v_Sigma_gal)\n",
    "ra_dec_summary_ = ra_dec_summary(v_vec, v_Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "936ebb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result, Equatorial Coordinates\n",
      "------------------------------\n",
      "  |g| (μas/yr)        : 5.4654\n",
      "  g (μas/yr)          : [ 0.02362784 -5.229347   -1.5886097 ]\n",
      "  |sigma_g| (μas/yr)  : 0.3019\n",
      "  sigma_g (μas/yr)    : [0.39327432 0.31327942 0.1983548 ]\n",
      "  Corr_gx_gy          : -0.0731\n",
      "  Corr_gx_gz          : -0.0149\n",
      "  Corr_gy_gz          : -0.0609\n",
      "  RA (deg)            : 270.2589\n",
      "  Sigma_RA (deg)      : 4.3077\n",
      "  Dec (deg)           : -16.8980\n",
      "  Sigma_Dec (deg)     : 2.2590\n",
      "  Corr_RA_dec         : 0.0078\n",
      "\n",
      "Results, Galactic Coordinates\n",
      "-----------------------------\n",
      "  |g|_gal (μas/yr)    : 5.4654\n",
      "  g_gal (μas/yr)      : [5.33483435 1.1511802  0.29092886]\n",
      "  |sigma_g_gal| (μas/yr): 0.3019\n",
      "  sigma_g_gal (μas/yr): [0.28359563 0.29112217 0.35633511]\n",
      "  Corr_g_galx_g_galy  : 0.3072\n",
      "  Corr_g_galx_g_galz  : 0.0933\n",
      "  Corr_g_galy_g_galz  : -0.4341\n",
      "  l (deg)             : 12.1769\n",
      "  Sigma_l (deg)       : 2.8578\n",
      "  b (deg)             : 3.0514\n",
      "  Sigma_b (deg)       : 3.7346\n",
      "  Corr_l_b            : -0.0085\n"
     ]
    }
   ],
   "source": [
    "print_summary(summary_norm, title='Result, Equatorial Coordinates')\n",
    "print_summary(ra_dec_summary_)\n",
    "print('')\n",
    "print_summary(summary_norm_gal, title='Results, Galactic Coordinates')\n",
    "print_summary(lb_summary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
